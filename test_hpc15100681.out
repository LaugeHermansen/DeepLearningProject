True

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 15100681: <test_hpc> in cluster <dcc> Done

Job <test_hpc> was submitted from host <n-62-27-17> by user <s204111> in cluster <dcc> at Sat Dec 24 06:04:41 2022
Job was executed on host(s) <n-62-20-14>, in queue <gpuv100>, as user <s204111> in cluster <dcc> at Sat Dec 24 06:29:46 2022
</zhome/56/e/155505> was used as the home directory.
</zhome/56/e/155505/Desktop/DeepLearningProject> was used as the working directory.
Started at Sat Dec 24 06:29:46 2022
Terminated at Sat Dec 24 06:29:51 2022
Results reported at Sat Dec 24 06:29:51 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
#BSUB -q gpuv100
#BSUB -gpu "num=1:mode=exclusive_process"
#BSUB -J test_hpc
#BSUB -n 1
#BSUB -R "rusage[mem=1GB]"
#BSUB -R "span[hosts=1]" 
#BSUB -o test_hpc%J.out
#BSUB -e test_hpc%J.err
#BSUB -W 0:05
# -- end of LSF options --

source diffwave/bin/activate
module load pandas/1.4.4-python-3.10.7
module load numpy/1.23.3-python-3.10.7-openblas-0.3.21
module load matplotlib/3.6.0-numpy-1.23.3-python-3.10.7
module load cuda


python Christians_seje_hpc_scripts/test_gpu.py

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1.83 sec.
    Max Memory :                                 -
    Average Memory :                             -
    Total Requested Memory :                     1024.00 MB
    Delta Memory :                               -
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   6 sec.
    Turnaround time :                            1510 sec.

The output (if any) is above this job summary.



PS:

Read file <test_hpc15100681.err> for stderr output of this job.

